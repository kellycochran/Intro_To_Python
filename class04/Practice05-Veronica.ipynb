{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice:  <br>PSET 1 Comments, <br>More Sophiticated Reading/Writing Files, &<br> Importing Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**12/2/2019<br>\n",
    "BIOS 274: Introductory Python Programming for Genomics**<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [PSET 1: Some comments](#PSET1)<br>\n",
    "2. [Let's practice!](#practice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"PSET1\"></a>\n",
    "## PSET 1: Some comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_fasta(fasta_filename):\n",
    "    '''\n",
    "    Go through file, reading one line at a time, using a\n",
    "    dictionary to store the DNA sequence for each of the FASTA\n",
    "    entries (Gavin Sherlock, November 28, 2019)\n",
    "    '''    \n",
    "    with open(fasta_filename, mode='r') as fasta_file:\n",
    "\n",
    "        sequences = {}\n",
    "        \n",
    "        for line in fasta_file:\n",
    "            line = line.rstrip()\n",
    "            if line.startswith('>'): # it's a new fasta record\n",
    "                line = line.lstrip('>')\n",
    "                sequences[line] = '' # intialize dictionary for this entry\n",
    "                currSeqName = line\n",
    "            else:\n",
    "                sequences[currSeqName] += line\n",
    "\n",
    "    return(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enzyme_sites = {'EcoRI': 'GAATTC', 'HindIII': 'AAGCTT',\n",
    "                'BamHI': 'GGATCC', 'HpaI': 'GTTAAC',\n",
    "                'HaeIII': 'GGCC'}\n",
    "\n",
    "cutsite_offset = {'EcoRI': 1, 'HindIII': 1, 'BamHI': 1,\n",
    "                  'HpaI': 3, 'HaeIII': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta_filename = 'rosalind_dna.fsa'\n",
    "read_seqs = read_fasta(fasta_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outFileName = 'PS1_Part1.txt'\n",
    "\n",
    "with open(outFileName, 'w') as outFile: # open the output file\n",
    "    for seqName, fastaSeq in read_seqs.items(): # go through each DNA sequence\n",
    "\n",
    "        numCut = 0 # initialize a varible to count how many enzymes cut the sequence\n",
    "        \n",
    "        outFile.write('Sequence: ' + seqName + ' (cut sites)\\n') # write the sequene name to the outFile\n",
    "        print('Sequence: ' + seqName + ' (cut sites)')\n",
    "\n",
    "        for enzName, enzSeq in enzyme_sites.items(): # go throught each enzyme\n",
    "            cutsiteList = [] # initialize a list to store all the cutsites for this particular DNA sequence and enzyme\n",
    "            enzOffset = cutsite_offset[enzName] # look up the offset for this particular enzyme\n",
    "\n",
    "            # find all the cutsites for for this particulare DNA sequence and enzyme and store in list\n",
    "            for i in range(len(fastaSeq)):\n",
    "                if fastaSeq[i:].startswith(enzSeq):\n",
    "                    cutsiteList.append(str(i + enzOffset))\n",
    "            \n",
    "            # only if there's a cutsite in the list (cutsiteList isn't empty), print out the enzyme name and the cutsites\n",
    "            if cutsiteList:\n",
    "                outFile.write(enzName + '\\t' + ', '.join(cutsiteList) + '\\n')\n",
    "                print(enzName + '\\t' + ', '.join(cutsiteList))\n",
    "                numCut += 1\n",
    "        \n",
    "        # only if no enzymes at all cut this DNA sequence (numCut == 0), print out that there are no cutsites found\n",
    "        if not numCut:\n",
    "            outFile.write('no cutsites found\\n')\n",
    "            print('no cutsites found')\n",
    "            \n",
    "        outFile.write('\\n')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's best **not to repeat code**!\n",
    "\n",
    "Other options:<br>\n",
    ">**1. Store the cutsite info from Part 1 in a variable (maybe a dictionaries within dictionaries) and use that variable in Part 2.**<br><br>\n",
    "<code>{'Rosalind_6820': {'HpaI': ['118'], 'HaeIII': ['596']}, \n",
    " 'Rosalind_3684': {'HaeIII': ['106', '121', '263', '408', '800', '916']}, \n",
    " 'Rosalind_6908': {}, \n",
    " 'Rosalind_2711': {'HindIII': ['133'], 'HaeIII': ['70', '225', '614', '628']}, \n",
    " 'Rosalind_1559': {'EcoRI': ['367'], 'HaeIII': ['91', '429', '458', '614', '622']}, \n",
    " 'Rosalind_9546': {}, \n",
    " 'Rosalind_5746': {'EcoRI': ['143'], 'HindIII': ['37'], 'BamHI': ['552'], 'HpaI': ['826'], 'HaeIII': ['177', '250', '272', '329', '409', '708']}}</code><br><br>\n",
    " \n",
    ">**2. Open two output files (instead of just one) at the beginning of your loop.\n",
    "<br>Write some information to one of the files and different information to the other file.**<br><br>\n",
    "<code>outFileName1 = 'PS1_part1.txt'\n",
    "outFileName2 = 'PS1_part2.txt'</code><br><br>\n",
    "<code>with open(outFileName1, 'w') as outFile1, open(outFileName2, 'w') as outFile2:</code><br>\n",
    "<code>    # FIND CUTSITES</code><br>\n",
    "<code>    # FIND FRAGMENT LENGTHS</code><br>\n",
    "<code>    outFile1.write('CUTSITE INFO')</code><br>\n",
    "<code>    outFile2.write('FRAGMENT LENGTH INFO')</code><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 - Improved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outFileName = 'PS1_Part1.txt'\n",
    "\n",
    "##### ADDED THIS\n",
    "cutsiteDict = {}\n",
    "\n",
    "with open(outFileName, 'w') as outFile:\n",
    "    for seqName, fastaSeq in read_seqs.items():\n",
    "\n",
    "        ##### ADDED THIS\n",
    "        cutsiteDict[seqName] = {}\n",
    "        \n",
    "        outFile.write('Sequence: ' + seqName + ' (cut sites)\\n')\n",
    "        print('Sequence: ' + seqName + ' (cut sites)')\n",
    "\n",
    "        for enzName, enzSeq in enzyme_sites.items():\n",
    "            cutsiteList = []\n",
    "            enzOffset = cutsite_offset[enzName]\n",
    "\n",
    "            for i in range(len(fastaSeq)):\n",
    "                if fastaSeq[i:].startswith(enzSeq):\n",
    "                    cutsiteList.append(str(i + enzOffset))\n",
    "\n",
    "            if cutsiteList:\n",
    "                ##### ADDED THIS\n",
    "                cutsiteDict[seqName][enzName] = cutsiteList\n",
    "                outFile.write(enzName + '\\t' + ', '.join(cutsiteList) + '\\n')\n",
    "                print(enzName + '\\t' + ', '.join(cutsiteList))\n",
    "        \n",
    "        ##### MADE THIS CHECK BETTER (no need for counting for how many enzymes cut andymore)\n",
    "        if not cutsiteDict[seqName]:\n",
    "            outFile.write('no cutsites found\\n')\n",
    "            print('no cutsites found')\n",
    "            \n",
    "        outFile.write('\\n')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutsiteDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"practice\"></a>\n",
    "## Let's Practice!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Day 5 folder on Canvas, there are  BED files that contain all the peaks found from ChIP-seq experiments done for various transcription factors in various cell types.\n",
    "\n",
    ">**1.** Without hardcoding the file names, find (and store in a variable) the names of all the BED files in the directory you downloaded from Canvas (Day 5).<br>\n",
    ">**2.** For each transcription factor tested in each cell type, generate a tab-delimited file (with an informative header) called <code>numPeaks.tsv</code> with:<br>\n",
    ">>**a.** the cell type used<br>\n",
    ">>**b.** the transcription factor tested<br>\n",
    ">>**c.** the number of ChIP-seq peaks within a genomic region of interest (in this case, chr2:47000000-48000000).\n",
    "\n",
    "i.e.<br> \n",
    "<code>TF_NAME</code>&nbsp;&nbsp;&nbsp;<code>CELL_TYPE</code>&nbsp;&nbsp;&nbsp;&nbsp;<code>COUNT_IN_ROI</code><br>\n",
    "<code>FOXA1</code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>K562</code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>2</code><br>\n",
    "<code>JUND</code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>GM12878</code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>7</code><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR SOLUTION HERE\n",
    "\n",
    "chromOfInterest = 'chr2'\n",
    "startOfInterest = 47000000\n",
    "endOfInterest = 48000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
